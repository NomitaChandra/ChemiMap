{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER - ConNER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT RUN THIS FILE - USE IN DOCKER CONTAINER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import ast \n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for datasets\n",
    "\n",
    "datapath = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train dataset: (500, 13)\n",
      "Shape of validation dataset: (500, 13)\n",
      "Shape of test dataset: (500, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_code</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>chemicals</th>\n",
       "      <th>diseases</th>\n",
       "      <th>chemical_start_indices</th>\n",
       "      <th>chemical_end_indices</th>\n",
       "      <th>disease_start_indices</th>\n",
       "      <th>disease_end_indices</th>\n",
       "      <th>chemical_ids</th>\n",
       "      <th>disease_ids</th>\n",
       "      <th>CID_chemical</th>\n",
       "      <th>CID_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227508</td>\n",
       "      <td>Naloxone reverses the antihypertensive effect ...</td>\n",
       "      <td>In unanesthetized, spontaneously hypertensive ...</td>\n",
       "      <td>['Naloxone', 'clonidine', 'clonidine', 'nalozo...</td>\n",
       "      <td>['hypertensive', 'hypotensive', 'hypertensive'...</td>\n",
       "      <td>['0', '49', '181', '244', '306', '354', '364',...</td>\n",
       "      <td>['8', '58', '190', '252', '322', '362', '372',...</td>\n",
       "      <td>['93', '274', '469', '750']</td>\n",
       "      <td>['105', '285', '481', '762']</td>\n",
       "      <td>['D009270', 'D003000', 'D003000', '-1', 'D0087...</td>\n",
       "      <td>['D006973', 'D007022', 'D006973', 'D006973']</td>\n",
       "      <td>['D008750']</td>\n",
       "      <td>['D007022']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>354896</td>\n",
       "      <td>Lidocaine-induced cardiac asystole.</td>\n",
       "      <td>Intravenous administration of a single 50-mg b...</td>\n",
       "      <td>['Lidocaine', 'lidocaine', 'lidocaine']</td>\n",
       "      <td>['cardiac asystole', 'depression', 'bradyarrhy...</td>\n",
       "      <td>['0', '90', '409']</td>\n",
       "      <td>['9', '99', '418']</td>\n",
       "      <td>['18', '142', '331']</td>\n",
       "      <td>['34', '152', '347']</td>\n",
       "      <td>['D008012', 'D008012', 'D008012']</td>\n",
       "      <td>['D006323', 'D003866', 'D001919']</td>\n",
       "      <td>['D008012']</td>\n",
       "      <td>['D006323']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>435349</td>\n",
       "      <td>Suxamethonium infusion rate and observed fasci...</td>\n",
       "      <td>Suxamethonium chloride (Sch) was administered ...</td>\n",
       "      <td>['Suxamethonium', 'Suxamethonium chloride', 'S...</td>\n",
       "      <td>['fasciculations', 'tetanic', 'Fasciculations'...</td>\n",
       "      <td>['0', '80', '104', '312']</td>\n",
       "      <td>['13', '102', '107', '315']</td>\n",
       "      <td>['41', '265', '395', '483', '523', '538', '561...</td>\n",
       "      <td>['55', '272', '409', '496', '536', '544', '568...</td>\n",
       "      <td>['D013390', 'D013390', 'D013390', 'D013390']</td>\n",
       "      <td>['D005207', 'D013746', 'D005207', 'D005207', '...</td>\n",
       "      <td>['D013390']</td>\n",
       "      <td>['D005207']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_code                                              title  \\\n",
       "0        227508  Naloxone reverses the antihypertensive effect ...   \n",
       "1        354896                Lidocaine-induced cardiac asystole.   \n",
       "2        435349  Suxamethonium infusion rate and observed fasci...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  In unanesthetized, spontaneously hypertensive ...   \n",
       "1  Intravenous administration of a single 50-mg b...   \n",
       "2  Suxamethonium chloride (Sch) was administered ...   \n",
       "\n",
       "                                           chemicals  \\\n",
       "0  ['Naloxone', 'clonidine', 'clonidine', 'nalozo...   \n",
       "1            ['Lidocaine', 'lidocaine', 'lidocaine']   \n",
       "2  ['Suxamethonium', 'Suxamethonium chloride', 'S...   \n",
       "\n",
       "                                            diseases  \\\n",
       "0  ['hypertensive', 'hypotensive', 'hypertensive'...   \n",
       "1  ['cardiac asystole', 'depression', 'bradyarrhy...   \n",
       "2  ['fasciculations', 'tetanic', 'Fasciculations'...   \n",
       "\n",
       "                              chemical_start_indices  \\\n",
       "0  ['0', '49', '181', '244', '306', '354', '364',...   \n",
       "1                                 ['0', '90', '409']   \n",
       "2                          ['0', '80', '104', '312']   \n",
       "\n",
       "                                chemical_end_indices  \\\n",
       "0  ['8', '58', '190', '252', '322', '362', '372',...   \n",
       "1                                 ['9', '99', '418']   \n",
       "2                        ['13', '102', '107', '315']   \n",
       "\n",
       "                               disease_start_indices  \\\n",
       "0                        ['93', '274', '469', '750']   \n",
       "1                               ['18', '142', '331']   \n",
       "2  ['41', '265', '395', '483', '523', '538', '561...   \n",
       "\n",
       "                                 disease_end_indices  \\\n",
       "0                       ['105', '285', '481', '762']   \n",
       "1                               ['34', '152', '347']   \n",
       "2  ['55', '272', '409', '496', '536', '544', '568...   \n",
       "\n",
       "                                        chemical_ids  \\\n",
       "0  ['D009270', 'D003000', 'D003000', '-1', 'D0087...   \n",
       "1                  ['D008012', 'D008012', 'D008012']   \n",
       "2       ['D013390', 'D013390', 'D013390', 'D013390']   \n",
       "\n",
       "                                         disease_ids CID_chemical  CID_disease  \n",
       "0       ['D006973', 'D007022', 'D006973', 'D006973']  ['D008750']  ['D007022']  \n",
       "1                  ['D006323', 'D003866', 'D001919']  ['D008012']  ['D006323']  \n",
       "2  ['D005207', 'D013746', 'D005207', 'D005207', '...  ['D013390']  ['D005207']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "\n",
    "df_train = pd.read_csv(f'{datapath}' + 'OfficialTrainingSet1.csv')\n",
    "df_val = pd.read_csv(f'{datapath}' + 'OfficialValidationSet1.csv')\n",
    "df_test = pd.read_csv(f'{datapath}' + 'OfficialTestSet1.csv')\n",
    "\n",
    "print(\"Shape of train dataset:\", df_train.shape)\n",
    "print(\"Shape of validation dataset:\", df_val.shape)\n",
    "print(\"Shape of test dataset:\", df_test.shape)\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation functions\n",
    "\n",
    "def convert_col_to_list(string):\n",
    "    \"\"\"\n",
    "    Converts all string columns that look like lists (col index 3 to end) into actual lists \n",
    "    \"\"\"\n",
    "    return ast.literal_eval(string)\n",
    "\n",
    "\n",
    "def lowercase_cols(lst):\n",
    "    \"\"\"\n",
    "    Converts chemicals and diseases column to lowercase\n",
    "    \"\"\"\n",
    "    return [item.lower() for item in lst]\n",
    "\n",
    "\n",
    "def map_cid_to_chemical_name(row):\n",
    "    \"\"\"\n",
    "    Maps CID of chemical in the CID_chemical column into the actual name of the chemical\n",
    "    \"\"\"\n",
    "    cid_chemicals = row['CID_chemical']\n",
    "    chemical_ids = row['chemical_ids']\n",
    "    chemicals = row['chemicals']\n",
    "    \n",
    "    chemical_names = []\n",
    "    \n",
    "    for cid in cid_chemicals:\n",
    "        if cid in chemical_ids:\n",
    "            idx = chemical_ids.index(cid)\n",
    "            chemical_names.append(chemicals[idx])\n",
    "        else:\n",
    "            chemical_names.append('unknown')\n",
    "    \n",
    "    return chemical_names\n",
    "\n",
    "\n",
    "def map_cid_to_disease_name(row):\n",
    "    \"\"\"\n",
    "    Maps CID of disease in the CID_disease column into the actual name of the disease\n",
    "    \"\"\"\n",
    "    cid_diseases = row['CID_disease']\n",
    "    disease_ids = row['disease_ids']\n",
    "    diseases = row['diseases']\n",
    "    \n",
    "    disease_names = []\n",
    "    \n",
    "    for cid in cid_diseases:\n",
    "        if cid in disease_ids:\n",
    "            idx = disease_ids.index(cid) \n",
    "            disease_names.append(diseases[idx]) \n",
    "        else:\n",
    "            disease_names.append('unknown')\n",
    "    \n",
    "    return disease_names\n",
    "\n",
    "\n",
    "# Function to handle \"unknown\" for chemical names\n",
    "def map_cid_to_chemical_name_unknown(data):\n",
    "    '''\n",
    "    Addresses 'unknown' instances of CID_chemical_names caused by chemicals with pipe (|) notation\n",
    "    '''\n",
    "    chemical_id_map = {}\n",
    "    for i, row in data.iterrows():\n",
    "        for cid, chemical in zip(row['chemical_ids'], row['chemicals']):\n",
    "            chemical_id_map[cid] = chemical\n",
    "    \n",
    "    # Function to map \"unknown\" to the correct chemical name if possible\n",
    "    def resolve_unknown_chemical_name(cids):\n",
    "        names = []\n",
    "        for cid in cids:\n",
    "            # Split combined IDs (separated by '|') and check for matches in the map\n",
    "            split_ids = cid.split('|')\n",
    "            name = ' | '.join([chemical_id_map.get(split_id, 'unknown') for split_id in split_ids])\n",
    "            names.append(name)\n",
    "        return names\n",
    "\n",
    "    # Apply the function only to rows where CID_chemical_name has \"unknown\"\n",
    "    data['CID_chemical_name'] = data.apply(lambda row: resolve_unknown_chemical_name(row['CID_chemical']) \n",
    "                                       if 'unknown' in row['CID_chemical_name'] else row['CID_chemical_name'], axis=1)\n",
    "    return data\n",
    "\n",
    "# Function to handle \"Unknown\" for disease names\n",
    "def map_cid_to_disease_name_unknown(data):\n",
    "    '''\n",
    "    Addresses 'unknown' instances of CID_disease_names caused by diseases with pipe (|) notation\n",
    "    '''\n",
    "    disease_id_map = {}\n",
    "    for i, row in data.iterrows():\n",
    "        for cid, disease in zip(row['disease_ids'], row['diseases']):\n",
    "            disease_id_map[cid] = disease\n",
    "    \n",
    "    # Function to map \"unknown\" to the correct disease name if possible\n",
    "    def resolve_unknown_disease_name(cids):\n",
    "        names = []\n",
    "        for cid in cids:\n",
    "            # Split combined IDs (separated by '|') and check for matches in the map\n",
    "            split_ids = cid.split('|')\n",
    "            name = ' | '.join([disease_id_map.get(split_id, 'unknown') for split_id in split_ids])\n",
    "            names.append(name)\n",
    "        return names\n",
    "\n",
    "    # Apply the function only to rows where CID_disease_name has \"Unknown\"\n",
    "    data['CID_disease_name'] = data.apply(lambda row: resolve_unknown_disease_name(row['CID_disease']) \n",
    "                                      if 'unknown' in row['CID_disease_name'] else row['CID_disease_name'], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_code</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>chemicals</th>\n",
       "      <th>diseases</th>\n",
       "      <th>chemical_start_indices</th>\n",
       "      <th>chemical_end_indices</th>\n",
       "      <th>disease_start_indices</th>\n",
       "      <th>disease_end_indices</th>\n",
       "      <th>chemical_ids</th>\n",
       "      <th>disease_ids</th>\n",
       "      <th>CID_chemical</th>\n",
       "      <th>CID_disease</th>\n",
       "      <th>CID_chemical_name</th>\n",
       "      <th>CID_disease_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227508</td>\n",
       "      <td>Naloxone reverses the antihypertensive effect ...</td>\n",
       "      <td>In unanesthetized, spontaneously hypertensive ...</td>\n",
       "      <td>[naloxone, clonidine, clonidine, nalozone, alp...</td>\n",
       "      <td>[hypertensive, hypotensive, hypertensive, hype...</td>\n",
       "      <td>['0', '49', '181', '244', '306', '354', '364',...</td>\n",
       "      <td>['8', '58', '190', '252', '322', '362', '372',...</td>\n",
       "      <td>['93', '274', '469', '750']</td>\n",
       "      <td>['105', '285', '481', '762']</td>\n",
       "      <td>[D009270, D003000, D003000, -1, D008750, D0092...</td>\n",
       "      <td>[D006973, D007022, D006973, D006973]</td>\n",
       "      <td>[D008750]</td>\n",
       "      <td>[D007022]</td>\n",
       "      <td>[alpha-methyldopa]</td>\n",
       "      <td>[hypotensive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>354896</td>\n",
       "      <td>Lidocaine-induced cardiac asystole.</td>\n",
       "      <td>Intravenous administration of a single 50-mg b...</td>\n",
       "      <td>[lidocaine, lidocaine, lidocaine]</td>\n",
       "      <td>[cardiac asystole, depression, bradyarrhythmias]</td>\n",
       "      <td>['0', '90', '409']</td>\n",
       "      <td>['9', '99', '418']</td>\n",
       "      <td>['18', '142', '331']</td>\n",
       "      <td>['34', '152', '347']</td>\n",
       "      <td>[D008012, D008012, D008012]</td>\n",
       "      <td>[D006323, D003866, D001919]</td>\n",
       "      <td>[D008012]</td>\n",
       "      <td>[D006323]</td>\n",
       "      <td>[lidocaine]</td>\n",
       "      <td>[cardiac asystole]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>435349</td>\n",
       "      <td>Suxamethonium infusion rate and observed fasci...</td>\n",
       "      <td>Suxamethonium chloride (Sch) was administered ...</td>\n",
       "      <td>[suxamethonium, suxamethonium chloride, sch, sch]</td>\n",
       "      <td>[fasciculations, tetanic, fasciculations, fasc...</td>\n",
       "      <td>['0', '80', '104', '312']</td>\n",
       "      <td>['13', '102', '107', '315']</td>\n",
       "      <td>['41', '265', '395', '483', '523', '538', '561...</td>\n",
       "      <td>['55', '272', '409', '496', '536', '544', '568...</td>\n",
       "      <td>[D013390, D013390, D013390, D013390]</td>\n",
       "      <td>[D005207, D013746, D005207, D005207, D005207, ...</td>\n",
       "      <td>[D013390]</td>\n",
       "      <td>[D005207]</td>\n",
       "      <td>[suxamethonium]</td>\n",
       "      <td>[fasciculations]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_code                                              title  \\\n",
       "0        227508  Naloxone reverses the antihypertensive effect ...   \n",
       "1        354896                Lidocaine-induced cardiac asystole.   \n",
       "2        435349  Suxamethonium infusion rate and observed fasci...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  In unanesthetized, spontaneously hypertensive ...   \n",
       "1  Intravenous administration of a single 50-mg b...   \n",
       "2  Suxamethonium chloride (Sch) was administered ...   \n",
       "\n",
       "                                           chemicals  \\\n",
       "0  [naloxone, clonidine, clonidine, nalozone, alp...   \n",
       "1                  [lidocaine, lidocaine, lidocaine]   \n",
       "2  [suxamethonium, suxamethonium chloride, sch, sch]   \n",
       "\n",
       "                                            diseases  \\\n",
       "0  [hypertensive, hypotensive, hypertensive, hype...   \n",
       "1   [cardiac asystole, depression, bradyarrhythmias]   \n",
       "2  [fasciculations, tetanic, fasciculations, fasc...   \n",
       "\n",
       "                              chemical_start_indices  \\\n",
       "0  ['0', '49', '181', '244', '306', '354', '364',...   \n",
       "1                                 ['0', '90', '409']   \n",
       "2                          ['0', '80', '104', '312']   \n",
       "\n",
       "                                chemical_end_indices  \\\n",
       "0  ['8', '58', '190', '252', '322', '362', '372',...   \n",
       "1                                 ['9', '99', '418']   \n",
       "2                        ['13', '102', '107', '315']   \n",
       "\n",
       "                               disease_start_indices  \\\n",
       "0                        ['93', '274', '469', '750']   \n",
       "1                               ['18', '142', '331']   \n",
       "2  ['41', '265', '395', '483', '523', '538', '561...   \n",
       "\n",
       "                                 disease_end_indices  \\\n",
       "0                       ['105', '285', '481', '762']   \n",
       "1                               ['34', '152', '347']   \n",
       "2  ['55', '272', '409', '496', '536', '544', '568...   \n",
       "\n",
       "                                        chemical_ids  \\\n",
       "0  [D009270, D003000, D003000, -1, D008750, D0092...   \n",
       "1                        [D008012, D008012, D008012]   \n",
       "2               [D013390, D013390, D013390, D013390]   \n",
       "\n",
       "                                         disease_ids CID_chemical CID_disease  \\\n",
       "0               [D006973, D007022, D006973, D006973]    [D008750]   [D007022]   \n",
       "1                        [D006323, D003866, D001919]    [D008012]   [D006323]   \n",
       "2  [D005207, D013746, D005207, D005207, D005207, ...    [D013390]   [D005207]   \n",
       "\n",
       "    CID_chemical_name    CID_disease_name  \n",
       "0  [alpha-methyldopa]       [hypotensive]  \n",
       "1         [lidocaine]  [cardiac asystole]  \n",
       "2     [suxamethonium]    [fasciculations]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the data transformations functions to all three datasets\n",
    "\n",
    "list_columns = ['chemicals', 'diseases', 'chemical_ids', 'disease_ids', 'CID_chemical', 'CID_disease']\n",
    "for col in list_columns:\n",
    "    df_train[col] = df_train[col].apply(convert_col_to_list) \n",
    "    df_val[col] = df_val[col].apply(convert_col_to_list) \n",
    "    df_test[col] = df_test[col].apply(convert_col_to_list) \n",
    "\n",
    "df_train['chemicals'] = df_train['chemicals'].apply(lowercase_cols)\n",
    "df_train['diseases'] = df_train['diseases'].apply(lowercase_cols)\n",
    "df_val['chemicals'] = df_val['chemicals'].apply(lowercase_cols)\n",
    "df_val['diseases'] = df_val['diseases'].apply(lowercase_cols)\n",
    "df_test['chemicals'] = df_test['chemicals'].apply(lowercase_cols)\n",
    "df_test['diseases'] = df_test['diseases'].apply(lowercase_cols)\n",
    "\n",
    "df_train['CID_chemical_name'] = df_train.apply(map_cid_to_chemical_name, axis=1)\n",
    "df_train['CID_disease_name'] = df_train.apply(map_cid_to_disease_name, axis=1)\n",
    "df_val['CID_chemical_name'] = df_val.apply(map_cid_to_chemical_name, axis=1)\n",
    "df_val['CID_disease_name'] = df_val.apply(map_cid_to_disease_name, axis=1)\n",
    "df_test['CID_chemical_name'] = df_test.apply(map_cid_to_chemical_name, axis=1)\n",
    "df_test['CID_disease_name'] = df_test.apply(map_cid_to_disease_name, axis=1)\n",
    "\n",
    "df_train = map_cid_to_chemical_name_unknown(df_train)\n",
    "df_train = map_cid_to_disease_name_unknown(df_train)\n",
    "df_val = map_cid_to_chemical_name_unknown(df_val)\n",
    "df_val = map_cid_to_disease_name_unknown(df_val)\n",
    "df_test = map_cid_to_chemical_name_unknown(df_test)\n",
    "df_test = map_cid_to_disease_name_unknown(df_test)\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConNER Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies (local for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 24.7.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jwj00999/anaconda3/envs/conner\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.8\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bzip2-1.0.8                |       h4bc722e_7         247 KB  conda-forge\n",
      "    ca-certificates-2024.8.30  |       hbcca054_0         155 KB  conda-forge\n",
      "    ld_impl_linux-64-2.43      |       h712a8e2_1         654 KB  conda-forge\n",
      "    libgcc-14.1.0              |       h77fa898_1         827 KB  conda-forge\n",
      "    libgcc-ng-14.1.0           |       h69a702a_1          51 KB  conda-forge\n",
      "    libgomp-14.1.0             |       h77fa898_1         449 KB  conda-forge\n",
      "    libsqlite-3.46.1           |       hadc24fc_0         845 KB  conda-forge\n",
      "    libxcrypt-4.4.36           |       hd590300_1          98 KB  conda-forge\n",
      "    libzlib-1.3.1              |       h4ab18f5_1          60 KB  conda-forge\n",
      "    ncurses-6.5                |       he02047a_1         868 KB  conda-forge\n",
      "    openssl-3.3.2              |       hb9d3cd8_0         2.8 MB  conda-forge\n",
      "    pip-24.2                   |     pyh8b19718_1         1.2 MB  conda-forge\n",
      "    python-3.8.20              |h4a871b0_1_cpython        21.1 MB  conda-forge\n",
      "    setuptools-75.1.0          |     pyhd8ed1ab_0         759 KB  conda-forge\n",
      "    wheel-0.44.0               |     pyhd8ed1ab_0          57 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        30.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge None\n",
      "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu None\n",
      "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 None\n",
      "  ca-certificates    conda-forge/linux-64::ca-certificates-2024.8.30-hbcca054_0 None\n",
      "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_1 None\n",
      "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 None\n",
      "  libgcc             conda-forge/linux-64::libgcc-14.1.0-h77fa898_1 None\n",
      "  libgcc-ng          conda-forge/linux-64::libgcc-ng-14.1.0-h69a702a_1 None\n",
      "  libgomp            conda-forge/linux-64::libgomp-14.1.0-h77fa898_1 None\n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 None\n",
      "  libsqlite          conda-forge/linux-64::libsqlite-3.46.1-hadc24fc_0 None\n",
      "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 None\n",
      "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 None\n",
      "  libzlib            conda-forge/linux-64::libzlib-1.3.1-h4ab18f5_1 None\n",
      "  ncurses            conda-forge/linux-64::ncurses-6.5-he02047a_1 None\n",
      "  openssl            conda-forge/linux-64::openssl-3.3.2-hb9d3cd8_0 None\n",
      "  pip                conda-forge/noarch::pip-24.2-pyh8b19718_1 None\n",
      "  python             conda-forge/linux-64::python-3.8.20-h4a871b0_1_cpython None\n",
      "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 None\n",
      "  setuptools         conda-forge/noarch::setuptools-75.1.0-pyhd8ed1ab_0 None\n",
      "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 None\n",
      "  wheel              conda-forge/noarch::wheel-0.44.0-pyhd8ed1ab_0 None\n",
      "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-3.3.2        | 2.8 MB    | ##################################### | 100% \n",
      "libxcrypt-4.4.36     | 98 KB     | ##################################### | 100% \n",
      "setuptools-75.1.0    | 759 KB    | ##################################### | 100% \n",
      "ld_impl_linux-64-2.4 | 654 KB    | ##################################### | 100% \n",
      "libsqlite-3.46.1     | 845 KB    | ##################################### | 100% \n",
      "bzip2-1.0.8          | 247 KB    | ##################################### | 100% \n",
      "ca-certificates-2024 | 155 KB    | ##################################### | 100% \n",
      "libgcc-ng-14.1.0     | 51 KB     | ##################################### | 100% \n",
      "libzlib-1.3.1        | 60 KB     | ##################################### | 100% \n",
      "pip-24.2             | 1.2 MB    | ##################################### | 100% \n",
      "wheel-0.44.0         | 57 KB     | ##################################### | 100% \n",
      "libgomp-14.1.0       | 449 KB    | ##################################### | 100% \n",
      "python-3.8.20        | 21.1 MB   | ##################################### | 100% \n",
      "ncurses-6.5          | 868 KB    | ##################################### | 100% \n",
      "libgcc-14.1.0        | 827 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate conner\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !conda create -n conner python=3.8 --yes\n",
    "# !conda activate conner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp39-cp39-linux_x86_64.whl (2041.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m601.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp39-cp39-linux_x86_64.whl (23.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.9.0\n",
      "  Downloading torchaudio-0.9.0-cp39-cp39-manylinux1_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from torch==1.9.0+cu111) (4.3.0)\n",
      "Requirement already satisfied: numpy in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from torchvision==0.10.0+cu111) (1.24.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from torchvision==0.10.0+cu111) (9.2.0)\n",
      "Downloading torchaudio-0.9.0-cp39-cp39-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2\n",
      "    Uninstalling torch-2.1.2:\n",
      "      Successfully uninstalled torch-2.1.2\n",
      "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jwj00999/Documents/MIDS/capstone/capstone-chemimed/models\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/dmis-lab/ConNER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting charset-normalizer==2.0.12 (from -r ConNER/requirements.txt (line 1))\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting click==8.1.3 (from -r ConNER/requirements.txt (line 2))\n",
      "  Using cached click-8.1.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting docker-pycreds==0.4.0 (from -r ConNER/requirements.txt (line 3))\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting filelock==3.7.1 (from -r ConNER/requirements.txt (line 4))\n",
      "  Using cached filelock-3.7.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting flashtool==0.0.10 (from -r ConNER/requirements.txt (line 5))\n",
      "  Using cached flashtool-0.0.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gitdb==4.0.9 (from -r ConNER/requirements.txt (line 6))\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl.metadata (998 bytes)\n",
      "Collecting GitPython==3.1.27 (from -r ConNER/requirements.txt (line 7))\n",
      "  Using cached GitPython-3.1.27-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: idna==3.3 in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from -r ConNER/requirements.txt (line 8)) (3.3)\n",
      "Collecting inflect==5.6.0 (from -r ConNER/requirements.txt (line 9))\n",
      "  Using cached inflect-5.6.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting joblib==1.1.0 (from -r ConNER/requirements.txt (line 10))\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting numpy==1.22.4 (from -r ConNER/requirements.txt (line 11))\n",
      "  Using cached numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting pathtools==0.1.2 (from -r ConNER/requirements.txt (line 12))\n",
      "  Using cached pathtools-0.1.2-py3-none-any.whl\n",
      "Requirement already satisfied: promise==2.3 in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from -r ConNER/requirements.txt (line 13)) (2.3)\n",
      "Collecting protobuf==3.20.1 (from -r ConNER/requirements.txt (line 14))\n",
      "  Using cached protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (698 bytes)\n",
      "Collecting psutil==5.9.1 (from -r ConNER/requirements.txt (line 15))\n",
      "  Using cached psutil-5.9.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from -r ConNER/requirements.txt (line 16)) (2.8.2)\n",
      "Collecting pytorch-crf==0.7.2 (from -r ConNER/requirements.txt (line 17))\n",
      "  Using cached pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: PyYAML==6.0 in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from -r ConNER/requirements.txt (line 18)) (6.0)\n",
      "Collecting regex==2022.6.2 (from -r ConNER/requirements.txt (line 19))\n",
      "  Using cached regex-2022.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (39 kB)\n",
      "Collecting requests==2.27.1 (from -r ConNER/requirements.txt (line 20))\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting sacremoses==0.0.53 (from -r ConNER/requirements.txt (line 21))\n",
      "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
      "Collecting sentencepiece==0.1.96 (from -r ConNER/requirements.txt (line 22))\n",
      "  Using cached sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting sentry-sdk==1.5.12 (from -r ConNER/requirements.txt (line 23))\n",
      "  Using cached sentry_sdk-1.5.12-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting setproctitle==1.2.3 (from -r ConNER/requirements.txt (line 24))\n",
      "  Using cached setproctitle-1.2.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting shortuuid==1.0.9 (from -r ConNER/requirements.txt (line 25))\n",
      "  Using cached shortuuid-1.0.9-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: six==1.16.0 in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from -r ConNER/requirements.txt (line 26)) (1.16.0)\n",
      "Collecting smmap==5.0.0 (from -r ConNER/requirements.txt (line 27))\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tensorboardX==2.5.1 (from -r ConNER/requirements.txt (line 28))\n",
      "  Using cached tensorboardX-2.5.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tokenizers==0.7.0 (from -r ConNER/requirements.txt (line 29))\n",
      "  Using cached tokenizers-0.7.0.tar.gz (81 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm==4.64.0 (from -r ConNER/requirements.txt (line 30))\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers==2.9.0 (from -r ConNER/requirements.txt (line 31))\n",
      "  Using cached transformers-2.9.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting urllib3==1.26.9 (from -r ConNER/requirements.txt (line 32))\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl.metadata (46 kB)\n",
      "Collecting wandb==0.12.17 (from -r ConNER/requirements.txt (line 33))\n",
      "  Using cached wandb-0.12.17-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from requests==2.27.1->-r ConNER/requirements.txt (line 20)) (2022.9.14)\n",
      "Requirement already satisfied: setuptools in /home/jwj00999/anaconda3/lib/python3.9/site-packages (from wandb==0.12.17->-r ConNER/requirements.txt (line 33)) (75.1.0)\n",
      "Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Using cached flashtool-0.0.10-py3-none-any.whl (7.1 kB)\n",
      "Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Using cached GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Using cached inflect-5.6.0-py3-none-any.whl (33 kB)\n",
      "Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Using cached numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Using cached protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Using cached psutil-5.9.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "Using cached pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
      "Using cached regex-2022.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Using cached sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
      "Using cached setproctitle-1.2.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Using cached shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
      "Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Using cached tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Using cached transformers-2.9.0-py3-none-any.whl (635 kB)\n",
      "Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Using cached wandb-0.12.17-py2.py3-none-any.whl (1.8 MB)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[44 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-39/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-39/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-39/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-39/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-39/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-39/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m To update pip, run:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m and then retry package installation.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build tokenizers\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install -r ConNER/requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
